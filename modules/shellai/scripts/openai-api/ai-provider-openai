#!/usr/bin/env dash

# NAME
#  ai-provider-openai - Interface for OpenAI's /chat/completions endpoint.
#
# SYNOPSIS
#  ai-provider-openai <-m|--messages> <messages> [--no-stream] 
#
# DESCRIPTION
#  Low-level script calling the OpenAI API to get completions for a given
#  message chain.
#
#  See the OpenAI API reference for more details:
#  https://platform.openai.com/docs/api-reference/chat
#
# OPTIONS
#  -t|--temperature <temperature=0.7>
#   The sampling temperature to use when generating completions.
#   Higher values mean the model will take more risks.
#
#  --model <model=gpt-4-turbo-preview>
#   The model to use for generating completions.
#
#  -m|--messages <messages>
#   JSON array of objects with `role` and `content` fields.
#
#  --no-stream
#   Disable streaming response.
#
#  --debug
#   Enable debug mode.
#
#  --raw
#   Output raw response from OpenAI without any processing
#
# ENVIRONMENT
#  OPENAI_API_KEY
#   The API key used for authenticating with the OpenAI API. 
#
#  OPENAI_ORG_ID
#   The organization ID used for authenticating with the OpenAI API.
# 
# SEE ALSO
#  curl(1), jq(1)

# ╭───┤ Outside dependencies 
# ╰─
if [ -z "$OPENAI_API_KEY" ]; then
  echo "error: missing required environment variable OPENAI_API_KEY" >&2
  exit 1
fi

# ╭───┤ Input validation
# ╰─
should_stream="true"
should_output_raw=""
is_debug="$SHELLAI_DEBUG"
model="gpt-4-turbo-preview"
temperature="0.7"
max_tokens="4096"

while [ "$#" -gt 0 ]; do
  case $1 in
    --raw)
      should_output_raw="true"
    ;;
    --debug)
      is_debug="true"
    ;;
    --no-stream)
      should_stream=""
    ;;
    -mt|--max-tokens)
      if [ "$2" ] && [ "${2#-}" = "$2" ]; then
        max_tokens=$2; shift
      else
        echo 'error: argument --max-tokens requires value.' >&2
        exit 1
      fi
    ;;
    -msg|--messages)
      if [ "$2" ] && [ "${2#-}" = "$2" ]; then
        messages=$2; shift
      else
        echo 'error: argument --messages requires value.' >&2
        exit 1
      fi
    ;;
    -t|--temperature)
      if [ "$2" ] && [ "${2#-}" = "$2" ]; then
        temperature=$2; shift
      else
        echo 'error: argument --temperature requires value.' >&2
        exit 1
      fi
    ;;
    -m|--model)
      if [ "$2" ] && [ "${2#-}" = "$2" ]; then
        model=$2; shift
      else
        echo 'error: argument --model requires value.' >&2
        exit 1
      fi
    ;;
    --) shift; break ;;
    -?*) echo "error: unknown flag: $1" >&2; exit 1 ;;
    *) break ;;
  esac
  shift
done

if [ -z "$messages" ]; then
  messages=$(cat -)
fi

if [ -z "$messages" ]; then
  echo "error: missing -m|--messages argument or stdin input" >&2
  exit 1 
fi

# ╭───┤ Functions
# ╰─

# Extract the content from the streamed response chunks.
# - When streaming, OpenAI sends multiple JSON objects with the content of the
# completion.
# - Each chunk contains the string "data: " followed by the JSON object.
# - Last chunk, marking the end of the stream, contains the string "[DONE]".
extract_streaming_content() {
  sed --unbuffered --regexp-extended \
    -e 's/^data: //' \
    -e 's/\[DONE\]//g' \
    | jq --unbuffered --raw-output --join-output \
      'select(.choices[0].delta.content != null) | .choices[0].delta.content' 
}

# Extract the content string from the non-streamed response.
extract_content() {
  jq --unbuffered --raw-output \
    '.choices[0].message.content'
}

# ╭──────────────────────
# │ Main. Start here.
# ╰────────

if [ -n "$should_stream" ]; then
  curl_stream_flags="--no-buffer"
else
  # Workaround for curl throwing an error if an argument is empty. This ensures
  # curl_stream_flags is never empty, preventing "curl: option : blank argument
  # where content is expected".
  curl_stream_flags="--silent"
fi

if [ -n "$is_debug" ]; then 
  print-info -nb "should_stream: ${should_stream:-false}"
  print-info -nb "should_output_raw: ${should_output_raw:-false}"
  print-info -nb "temperature: $temperature"
  print-info -nb "model: $model"
fi

jq --compact-output --null-input \
  --argjson messages "$messages" \
  --arg max_tokens "$max_tokens" \
  --arg model "$model" \
  --arg temperature "$temperature" \
  --arg stream "$should_stream" \
  '{
    model: $model,
    stream: ($stream | test("true")),
    temperature: ($temperature | tonumber),
    max_tokens: $max_tokens | tonumber,
    messages: $messages | map(
      if .role | test("^system_") then
        .role = "system"
      else
        .
      end
    )
  }' \
 | curl --silent "$curl_stream_flags" \
  --data @- \
  --fail-with-body \
  --request POST \
  --header "Content-Type: application/json" \
  --header "Authorization: Bearer $OPENAI_API_KEY" \
  --header "OpenAI-Organization: $OPENAI_ORG_ID" \
    https://api.openai.com/v1/chat/completions \
  | if [ -n "$should_output_raw" ]; then
      cat
    else
      if [ -n "$should_stream" ]; then
        extract_streaming_content
      else
        extract_content
      fi
    fi
